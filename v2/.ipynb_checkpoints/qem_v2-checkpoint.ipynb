{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quotation Extraction: Version 2\n",
    "## 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import csv\n",
    "# spaCy\n",
    "import spacy\n",
    "# spaCy Visualizer\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Text processing\n",
    "### 1.1 Loading and cleaning the text file\n",
    "Loads the article, removes all new line characters and replaces all variants of quotes by a unique one. Puts the text through the NLP pipeline.\n",
    "\n",
    "I have also noticed that the model doesn't deal with \";\" symbols to seperate sentences, which it sometimes treats as the end of the sentence and sometimes not. I replace them with commas (\",\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/article.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d827e188db78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/article.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_quotes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/article.txt'"
     ]
    }
   ],
   "source": [
    "quotes = [\"«\", \"»\", \"“\", \"”\", \"„\", \"‹\", \"›\", \"‟\", \"〝\", \"〞\"]\n",
    "\n",
    "# Replace all formats of quotation marks by the quotation mark <\">\n",
    "def normalize_quotes(text):\n",
    "    for q in quotes:\n",
    "        text = text.replace(q, '\"')\n",
    "    return text\n",
    "\n",
    "\n",
    "with open('../data/article01.txt', 'r') as file:\n",
    "    text = normalize_quotes(file.read().replace('\\n', ' '))\n",
    "    text = text.replace(\";\", \",\")\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Splitting text into sentences\n",
    "Splits the text into a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Loading Model Parameters\n",
    "### 2.1 Loading cue verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cue_verbs.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    cue_verbs = set(list(reader)[0])\n",
    "\n",
    "print(cue_verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Loading Quotations Structures\n",
    "The quotation structures are stored in a CSV file, respecting the following format. All Part-Of-Speech elements are abbreviated as follows.\n",
    "* RS: Reported Speech\n",
    "* CV: Cue Verb\n",
    "* QT: Quotee\n",
    "* text: distinct words\n",
    "One structure per line, with each element seperated by a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/quote_structures.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    structures = list(reader)\n",
    "\n",
    "print(structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Finding quote containing sentences\n",
    "### 3.1 Finding sentences containing cue verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns true iff the sentence contains quotation marks.\n",
    "def contains_cue(sentence):\n",
    "    for token in sentence:\n",
    "        if token.lemma_ in cue_verbs:\n",
    "            return True\n",
    "\n",
    "\n",
    "cues = []\n",
    "        \n",
    "for s in sentences:\n",
    "    if contains_cue(s):\n",
    "        cues.append(s)\n",
    "        print(s, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Determining which sentences contain quotes\n",
    "Using the structures and cue verbs that were manually found, for each sentence containing a cue verb we output if a quote was found, or if no quote is in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_cue(sentence):\n",
    "    for token in sentence:\n",
    "        if token.lemma_ in cue_verbs:\n",
    "            return token\n",
    "\n",
    "def extract_quotee(token):\n",
    "    quotee = \"\"\n",
    "    for t in token.subtree:\n",
    "        quotee += t.text + t.whitespace_\n",
    "    return quotee\n",
    "\n",
    "def quote_text(token, cv_dep):\n",
    "    quote = \"\"\n",
    "    for t in token.lefts:\n",
    "        if t.dep_ != cv_dep:\n",
    "            quote += quote_text(t, cv_dep)\n",
    "    quote += token.text + token.whitespace_\n",
    "    for t in token.rights:\n",
    "        if t.dep_ != cv_dep:\n",
    "            quote += quote_text(t, cv_dep)\n",
    "    return quote\n",
    "\n",
    "def is_quote(sentence):\n",
    "    if contains_cue(sentence):\n",
    "        cv = extract_cue(sentence)\n",
    "        children = list(map(lambda t:t.dep_, list(cv.children)))\n",
    "        for struct in structures:\n",
    "            cv_dep = struct[0]\n",
    "            qt_pos = struct[1]\n",
    "            q_pos = struct[2]\n",
    "            if cv.dep_ == cv_dep and qt_pos in children:\n",
    "                for child in cv.children:\n",
    "                    if child.dep_ == qt_pos:\n",
    "                        qt_token = child\n",
    "                quotee = extract_quotee(qt_token)\n",
    "                if q_pos == \"ancestor\":\n",
    "                    quote = quote_text(next(cv.ancestors), cv_dep)\n",
    "                else:\n",
    "                    for child in cv.children:\n",
    "                        if child.dep_ == q_pos:\n",
    "                            q_token = child\n",
    "                    quote = quote_text(q_token, cv_dep)\n",
    "                return quotee + \" said \" + quote\n",
    "    return \"No quote in this sentence\"\n",
    "\n",
    "for s in cues:\n",
    "    print(\"Sentence:\\n\")\n",
    "    print(s.text, \"\\n\")\n",
    "    print(\"The result was:\\n\")\n",
    "    print(is_quote(s), \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
