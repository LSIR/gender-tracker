{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciLens Quote Extraction Model\n",
    "Taken from the SciLens git page. Slightly modified to fit my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading language model\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resolve the quotee of a quote.\n",
    "def resolveQuotee(quotee, sPerEntities, sOrgEntities, allPerEntities, allOrgEntities):\n",
    "    \n",
    "    q = qtype = qaff = 'unknown'\n",
    "    \n",
    "    #case that quotee PER entity exists\n",
    "    for e in sPerEntities:\n",
    "        if e in quotee:\n",
    "            q = e\n",
    "            qtype = 'PERSON'\n",
    "            \n",
    "            #find affiliation of person\n",
    "            for e in sOrgEntities:\n",
    "                if e in quotee:\n",
    "                    qaff = e\n",
    "                    break\n",
    "            \n",
    "            p = resolvePerson(q, allPerEntities)\n",
    "            if p != None:\n",
    "                q = p\n",
    "                        \n",
    "            return (q, qtype, qaff)    \n",
    "\n",
    "    #case that quotee ORG entity exists      \n",
    "    for e in sOrgEntities:\n",
    "\n",
    "        if e in quotee:\n",
    "            q = e\n",
    "            qtype = 'ORG'\n",
    "            qaff = e\n",
    "            \n",
    "            o = resolveOrganization(q, allOrgEntities)\n",
    "            if o != None:\n",
    "                q = o\n",
    "                qaff = o\n",
    "       \n",
    "            return (q, qtype, qaff)   \n",
    "        \n",
    "    #case that quotee entity doesn't exist\n",
    "    try:\n",
    "        noun = next(nlp(quotee).noun_chunks).root.lemma_\n",
    "    except:    \n",
    "        return (q, qtype, qaff)\n",
    "    \n",
    "    if noun in personKeywords:\n",
    "        q = qtype = qaff = 'unnamed person'\n",
    "    elif noun in studyKeywords:\n",
    "        q = qtype = qaff = 'unnamed study'\n",
    "    return (q, qtype, qaff)\n",
    "\n",
    "#Resolve cases where PERSON is referred to with his/her first or last name       \n",
    "def resolvePerson(per, plist):\n",
    "    if len(per.split()) == 1:\n",
    "        for p in plist:\n",
    "            if per != p and per in p.split():\n",
    "                #print(per, ' to ', p)\n",
    "                return p\n",
    "    return None\n",
    "\n",
    "#Resolve cases where ORG is referred to with an acronym\n",
    "def resolveOrganization(org, olist):\n",
    "    if len(org.split()) == 1:\n",
    "        for o in olist:\n",
    "            if org != o and len(o.split()) > 1:\n",
    "                fullAcronym = compactAcronym = upperAccronym = ''\n",
    "                for w in o.split():\n",
    "                    for l in w:\n",
    "                        if (l.isupper()):\n",
    "                            upperAccronym += l\n",
    "                    if not nlp(w)[0].is_stop:\n",
    "                        compactAcronym += w[0]\n",
    "                    fullAcronym += w[0]\n",
    "\n",
    "                if org.lower() in [fullAcronym.lower(), compactAcronym.lower(), upperAccronym.lower()]:\n",
    "                    #print(org, ' to ', o)\n",
    "                    return o\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for quote patterns\n",
    "def quote_pattern_search(article):\n",
    "\n",
    "    allPerEntities = []\n",
    "    allOrgEntities = []\n",
    "\n",
    "    doc = nlp(article)\n",
    "    \n",
    "    for e in doc.ents:\n",
    "        if e.label_ == 'PERSON':\n",
    "            allPerEntities.append(e.text)\n",
    "        elif e.label_ == 'ORG':\n",
    "            allOrgEntities.append(e.text)\n",
    "            \n",
    "    quotes = []\n",
    "\n",
    "    for s in list(doc.sents):\n",
    "        quoteFound = False\n",
    "        quote = quotee = quoteeType = quoteeAffiliation = \"\"\n",
    "\n",
    "        sPerEntities = []\n",
    "        sOrgEntities = []\n",
    "        for e in s.ents:\n",
    "            if e.label_ == 'PERSON':\n",
    "                sPerEntities.append(e.text)\n",
    "            elif e.label_ == 'ORG':\n",
    "                sOrgEntities.append(e.text)\n",
    "\n",
    "\n",
    "        #find all verbs of the sentence.\n",
    "        verbs = set()\n",
    "        for v in s:\n",
    "            if v.head.pos_ == 'VERB':\n",
    "                verbs.add(v.head)\n",
    "\n",
    "        if not verbs:\n",
    "            continue\n",
    "\n",
    "        rootVerb = ([w for w in s if w.head is w] or [None])[0]\n",
    "\n",
    "        #check first the root verb and then the others.\n",
    "        verbs = [rootVerb] + list(verbs)\n",
    "\n",
    "        for v in verbs:\n",
    "            if v is not None and v.lemma_ in actionsKeywords:            \n",
    "                print(v.lemma_)\n",
    "                for np in v.children:\n",
    "                    if np.dep_ == 'nsubj':\n",
    "                        quotee = s[np.left_edge.i : np.right_edge.i+1].text\n",
    "                        quote = s.text.strip()\n",
    "                        quotee, quoteeType, quoteeAffiliation = resolveQuotee(quotee, sPerEntities, sOrgEntities, allPerEntities, allOrgEntities)\n",
    "                        if quotee != 'unknown':\n",
    "                            quoteFound = True\n",
    "                            quotes.append({'quote': quote, 'quotee':quotee, 'quoteeType':quoteeType, 'quoteeAffiliation':quoteeAffiliation})\n",
    "                            break\n",
    "\n",
    "            if quoteFound:\n",
    "                break\n",
    "                \n",
    "    return quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quote indicators\n",
    "def quote_indicators(quotes):\n",
    "    count_PER_quotes = 0\n",
    "    count_ORG_quotes = 0\n",
    "    count_unnamed_quotes = 0\n",
    "    count_all_quotes = 0\n",
    "    for q in quotes:\n",
    "        if q['quoteeType'] == 'PERSON':\n",
    "            count_PER_quotes += 1\n",
    "        if q['quoteeType'] == 'ORG':\n",
    "            count_ORG_quotes += 1\n",
    "        if 'unnamed' in q['quoteeType']:\n",
    "            count_unnamed_quotes += 1\n",
    "    count_all_quotes = count_PER_quotes + count_ORG_quotes + count_unnamed_quotes\n",
    "    return {'count_all_quotes':count_all_quotes, 'count_PER_quotes':count_PER_quotes, 'count_ORG_quotes':count_ORG_quotes, 'count_unnamed_quotes':count_unnamed_quotes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exract quotes from articles\n",
    "def extract_quotes(article_in_file, article_out_file):\n",
    "\n",
    "    global nlp, personKeywords, studyKeywords, actionsKeywords\n",
    "    nlp = spacy.load('en')\n",
    "    personKeywords = open(personKeywordsFile).read().splitlines()\n",
    "    studyKeywords = open(studyKeywordsFile).read().splitlines()\n",
    "    actionsKeywords = open(actionsKeywordsFile).read().splitlines()\n",
    "\n",
    "\n",
    "    df = pd.read_csv(article_in_file, sep='\\t')\n",
    "    df['quotes'] = df['full_text'].apply(lambda x : quote_pattern_search(x))\n",
    "    df['quote_indicators'] = df['quotes'].apply(lambda x : quote_indicators(x))\n",
    "    df.to_csv(article_out_file, sep='\\t', index=None)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observer\n",
      "publier\n",
      "rapporter\n",
      "montrer\n",
      "rapporter\n",
      "souligner\n",
      "soutenir\n",
      "raconter\n",
      "expliquer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes = [\"«\", \"»\", \"“\", \"”\", \"„\", \"‹\", \"›\", \"‟\", \"〝\", \"〞\"]\n",
    "\n",
    "# Replace all formats of quotation marks by the quotation mark <\">\n",
    "def normalize_quotes(text):\n",
    "    for q in quotes:\n",
    "        text = text.replace(q, '\"')\n",
    "    return text\n",
    "\n",
    "global studyKeywords, actionsKeywords\n",
    "\n",
    "with open('../data/cue_verbs.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    studyKeywords = set(list(reader)[0])\n",
    "    actionsKeywords = studyKeywords\n",
    "\n",
    "with open('../data/article01.txt', 'r') as file:\n",
    "    text = normalize_quotes(file.read().replace('\\n', ' '))\n",
    "    text = text.replace(\";\", \",\")\n",
    "\n",
    "quote_pattern_search(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
