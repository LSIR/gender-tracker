{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quotation Extraction: Version 3\n",
    "## 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import csv\n",
    "# spaCy\n",
    "import spacy\n",
    "# spaCy Visualizer\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_boundaries(doc):\n",
    "    \"\"\"\n",
    "    Custom boundaries so that spaCy doesn't split sentences at ';' or at '-[A-Z]'.\n",
    "    \"\"\"\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \";\":\n",
    "            doc[token.i+1].is_sent_start = False\n",
    "        if token.text == \"-\" and token.i != 0:\n",
    "            doc[token.i].is_sent_start = False\n",
    "    return doc\n",
    "\n",
    "\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "nlp.add_pipe(set_custom_boundaries, before=\"parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Text processing\n",
    "### 1.1 Loading and cleaning the text file\n",
    "Loads the article, removes all new line characters and replaces all variants of quotes by a unique one. Puts the text through the NLP pipeline.\n",
    "\n",
    "I have also noticed that the model doesn't deal with \";\" symbols to seperate sentences, which it sometimes treats as the end of the sentence and sometimes not. I replace them with commas (\",\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = [\"«\", \"»\", \"“\", \"”\", \"„\", \"‹\", \"›\", \"‟\", \"〝\", \"〞\"]\n",
    "\n",
    "# Replace all formats of quotation marks by the quotation mark <\">\n",
    "def normalize_quotes(text):\n",
    "    for q in quotes:\n",
    "        text = text.replace(q, '\"')\n",
    "    return text\n",
    "\n",
    "\n",
    "with open('../data/article01.txt', 'r') as file:\n",
    "    text = normalize_quotes(file.read().replace('\\n', ' '))\n",
    "    text = text.replace(\";\", \",\")\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Loading Model Parameters\n",
    "### 2.1 Loading cue verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cue_verbs.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    cue_verbs = set(list(reader)[0])\n",
    "\n",
    "print(cue_verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Loading Quotations Structures\n",
    "The quotation structures are stored in a CSV file, respecting the following format. All Part-Of-Speech elements are abbreviated as follows.\n",
    "* RS: Reported Speech\n",
    "* CV: Cue Verb\n",
    "* QT: Quotee\n",
    "* text: distinct words\n",
    "One structure per line, with each element seperated by a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/quote_structures.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    structures = list(reader)\n",
    "\n",
    "print(structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Finding quote containing sentences\n",
    "### 3.1 Finding sentences containing direct quotes, and replacing the quotes with special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_quote(text):\n",
    "    # Quote at least 3 tokens long\n",
    "    a = len(text) >= 3\n",
    "    # Non-proper noun words are not all capitalized \n",
    "    b = [word.shape_[0] == 'X' for word in text if not word.pos_ in [\"PROPN\", \"PUNCT\"]]\n",
    "    return a and (False in b)\n",
    "\n",
    "def quote_finder(text):\n",
    "    matcher = Matcher(nlp.vocab, validate=True)\n",
    "    # Add match ID \"Quote\"\n",
    "    pattern = [{\"TEXT\": '\"'}]\n",
    "    matcher.add(\"Quote\", None, pattern)\n",
    "\n",
    "    # Find the quote matches\n",
    "    matches = matcher(text)\n",
    "    opening_quotes = []\n",
    "    closing_quotes = []\n",
    "    for match_id, start, end in matches:\n",
    "        if len(opening_quotes) == len(closing_quotes):\n",
    "            opening_quotes.append(start)\n",
    "        else:\n",
    "            closing_quotes.append(start + 1)\n",
    "\n",
    "    quote_pos = zip(opening_quotes, closing_quotes)\n",
    "    potential_quotes = []\n",
    "    for (start, end) in quote_pos:\n",
    "        quote = text[start:end]\n",
    "        if is_quote(quote):\n",
    "            potential_quotes.append((start, end))\n",
    "    return potential_quotes\n",
    "\n",
    "def encode_quotes(text):\n",
    "    potential_quotes = quote_finder(text)\n",
    "    encoded_text = \"\"\n",
    "    prev_quote_end = 0\n",
    "    for (start, end) in potential_quotes:\n",
    "        encoded_text += text[prev_quote_end:start].text\n",
    "        encoded_text += \" * \"\n",
    "        prev_quote_end = end\n",
    "    encoded_text += text[prev_quote_end:].text\n",
    "    return encoded_text\n",
    "\n",
    "encoded_text = encode_quotes(doc)\n",
    "encoded_doc = nlp(encoded_text)\n",
    "encoded_sentences = list(encoded_doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns true iff the sentence contains quotation marks.\n",
    "def contains_cue(sentence):\n",
    "    for token in sentence:\n",
    "        if token.lemma_ in cue_verbs:\n",
    "            return True\n",
    "\n",
    "def contains_quotes(sentence):\n",
    "    for token in sentence:\n",
    "        if token.text == '*':\n",
    "            return True\n",
    "\n",
    "cues = []\n",
    "        \n",
    "for s in encoded_sentences:\n",
    "    if contains_cue(s) and contains_quotes(s):\n",
    "        cues.append(s)\n",
    "        print(s, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Observing the structure of encoded sentences containing cue verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in cues:\n",
    "    displacy.render(s, style=\"dep\", options={\"compact\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Extracting Named Entites that are the object of the sentence\n",
    "Extracting Named Entities by simply returning named entities that are children of the cue verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cue_verb(sentence):\n",
    "    for token in sentence:\n",
    "        if token.lemma_ in cue_verbs:\n",
    "            return token\n",
    "\n",
    "def extract_quotee(token):\n",
    "    quotee = \"\"\n",
    "    for t in token.subtree:\n",
    "        quotee += t.text + t.whitespace_\n",
    "    return quotee\n",
    "        \n",
    "def find_quotes(encoded_doc):\n",
    "    encoded_sentences = list(encoded_doc.sents)\n",
    "    for s in encoded_sentences:\n",
    "        if contains_cue(s) and contains_quotes(s):\n",
    "            cv = extract_cue_verb(s)\n",
    "            quotee = None\n",
    "            for child in cv.children:\n",
    "                if child.pos_ == \"PROPN\" and quotee is None:\n",
    "                    quotee = extract_quotee(child)\n",
    "            print(\"In <\", s, \">, the quotee was\", quotee)\n",
    "\n",
    "find_quotes(encoded_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how everything works for the second article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/article02.txt', 'r') as file2:\n",
    "    text2 = normalize_quotes(file2.read().replace('\\n', ' '))\n",
    "    text2 = text2.replace(\";\", \",\")\n",
    "\n",
    "doc2 = nlp(text2)\n",
    "encoded_text2 = encode_quotes(doc2)\n",
    "encoded_doc2 = nlp(encoded_text2)\n",
    "encoded_sentences2 = list(encoded_doc2.sents)\n",
    "find_quotes(encoded_doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining why the sentence:\n",
    "\n",
    "«Aujourd’hui, à Mopti, tout le monde a un peu tort et personne n’a vraiment raison», sourit tristement Ousmane.\n",
    "\n",
    "isn't detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourir = '«Aujourd’hui, à Mopti, tout le monde a un peu tort et personne n’a vraiment raison», sourit tristement Ousmane.'\n",
    "test_sourir = nlp(sourir)\n",
    "displacy.render(test_sourir, style=\"dep\", options={\"compact\": True})\n",
    "sourir2 = '*, sourit tristement Ousmane.'\n",
    "test_sourir2 = nlp(sourir2)\n",
    "displacy.render(test_sourir2, style=\"dep\", options={\"compact\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining why the sentence:\n",
    "\n",
    "«Beaucoup de jeunes partent. Il n’y a rien à faire ici», lâche Arkietou Diallo, 22 ans, seconde fille d’Ousmane.\n",
    "\n",
    "isn't detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lacher = '«Beaucoup de jeunes partent. Il n’y a rien à faire ici», lâche Arkietou Diallo, 22 ans, seconde fille d’Ousmane.'\n",
    "test_lacher = nlp(lacher)\n",
    "\n",
    "for token in test_lacher:\n",
    "    if token.text==\"lâche\":\n",
    "        print(\"lâche has\", token.lemma_, \"as the lemma.\")\n",
    "\n",
    "displacy.render(test_lacher, style=\"dep\", options={\"compact\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining why the sentence:\n",
    "\n",
    "«C’est comme une moustiquaire», murmure-t-il en me fixant.\n",
    "\n",
    "isn't detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "murmurer = '«C’est comme une moustiquaire», murmure-t-il en me fixant.'\n",
    "test_murmurer = nlp(murmurer)\n",
    "\n",
    "for token in test_murmurer:\n",
    "    if token.text==\"murmure\":\n",
    "        print(\"murmure has\", token.lemma_, \"as the lemma.\")\n",
    "\n",
    "displacy.render(test_murmurer, style=\"dep\", options={\"compact\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining why the sentence:\n",
    "\n",
    "«Une agriculture utile», ricane Ousmane.\n",
    "\n",
    "isn't detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ricaner = '«Une agriculture utile», ricane Ousmane.'\n",
    "test_ricaner = nlp(ricaner)\n",
    "\n",
    "for token in test_ricaner:\n",
    "    if token.text==\"ricane\":\n",
    "        print(\"ricane has\", token.lemma_, \"as the lemma.\")\n",
    "\n",
    "displacy.render(test_ricaner, style=\"dep\", options={\"compact\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
