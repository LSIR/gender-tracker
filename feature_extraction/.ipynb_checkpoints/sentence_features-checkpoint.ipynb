{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of features for quote detection\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import csv \n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "### SpaCy POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CCONJ', 'PUNCT', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'PUNCT', 'DET', 'ADV']\n",
      "[89, 97, 90, 92, 85, 84, 92, 97, 90, 86]\n",
      "[5, 13, 6, 8, 1, 0, 8, 13, 6, 2, 0, 5, 1, 11, 16, 1, 6, 8, 13, 13, 16, 12, 12, 13, 1, 6, 8, 1, 12, 13]\n",
      "['CCONJ___', 'PUNCT___']\n",
      "[8673025306212932083, 16177087412692307460]\n"
     ]
    }
   ],
   "source": [
    "POS_TAGS = ['ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET',\\\n",
    "            'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT',\\\n",
    "            'SCONJ', 'SYM', 'VERB', 'X', 'SPACE']\n",
    "\n",
    "NE_PER = 'PER'\n",
    "\n",
    "sentence = 'Mais \"les nuits de pleine lune, les plus claires d’entre elles resplendissent '\\\n",
    "            'comme des soleils\", observe Alexandre Roulin, de l’Université de Lausanne.'\n",
    "\n",
    "s = nlp(sentence)\n",
    "\n",
    "pos_tags = []\n",
    "pos_tags_int = []\n",
    "pos_tag_feature = []\n",
    "tag_tags = []\n",
    "tag_tags_int = []\n",
    "\n",
    "for token in s:\n",
    "    pos_tags.append(token.pos_)\n",
    "    pos_tags_int.append(token.pos)\n",
    "    pos_tag_feature.append(POS_TAGS.index(token.pos_))\n",
    "    tag_tags.append(token.tag_)\n",
    "    tag_tags_int.append(token.tag)\n",
    "    \n",
    "print(pos_tags[:10])\n",
    "print(pos_tags_int[:10])\n",
    "print(pos_tag_feature)\n",
    "print(tag_tags[:2])\n",
    "print(tag_tags_int[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s', murmurer, dénoncer, soutenir, élaborer, montrer, prôner, considérer, poursuivre, préciser, mettre, ajouter, identifier, crier, raconter, estimer, donner, concevoir, déplorer, écrire, corroborer, recenser, souvenir, prétendre, dire, résumer, calculer, commenter, sourir, définir, expliquer, proclamer, affirmer, lâcher, découvrir, prouver, souligner, déclarer, formuler, confirmer, mettre, observer, établir, rapporter, reconnaître, relever, remarquer, constater, annoncer, insister, répondre, abonder, démontrer, ricaner, adopter, étudier, présenter, se, citer, proposer, suggérer, exprimer, noter, décrire, analyser]\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "\n",
    "with open('../data/cue_verbs.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    cue_verbs = set(list(reader)[0])\n",
    "\n",
    "cue_verbs = [nlp(verb)[0] for verb in cue_verbs]\n",
    "print(cue_verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Given a sentence that needs to be classified as either a quote or not a quote, the sentences central verb (called the \"target\") needs to be extracted.\n",
    "\n",
    "### Verbe Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Mais, 0), (\", 0), (les, 1), (nuits, 1), (de, 1), (pleine, 1), (lune, 1), (,, 1), (les, 1), (plus, 1), (claires, 1), (d’, 1), (entre, 1), (elles, 1), (resplendissent, 1), (comme, 1), (des, 1), (soleils, 1), (\", 0), (,, 0), (observe, 0), (Alexandre, 0), (Roulin, 0), (,, 0), (de, 0), (l’, 0), (Université, 0), (de, 0), (Lausanne, 0), (., 0)]\n"
     ]
    }
   ],
   "source": [
    "def token_in_quotes(sentence):\n",
    "    \"\"\"\n",
    "    Returns a list, the same length as the number of tokens in the sentence, where each index is 0 if the\n",
    "    corresponding token isn't between quotes and 1 if it is.\n",
    "    \"\"\"\n",
    "    in_quote = 0\n",
    "    in_quotes = []\n",
    "    for token in sentence:\n",
    "        in_quotes.append(in_quote)\n",
    "        if token.text == '\"' and in_quote == 0:\n",
    "            in_quote = 1\n",
    "        elif token.text == '\"':\n",
    "            in_quote = 0\n",
    "            in_quotes[-1] = 0\n",
    "    return in_quotes\n",
    "\n",
    "in_quotes = token_in_quotes(s)\n",
    "print([z for z in zip(s, in_quotes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(20, 'observe', 1.0, observer)]\n",
      "(20, observe)\n"
     ]
    }
   ],
   "source": [
    "def verb_similarities(sentence, in_quotes, cue_verbs):\n",
    "    \"\"\"\n",
    "    Determines the minimum distance between each verbs that isn't between quotes in the sentence and a cue_verb.\n",
    "    Returns the index of each such verb, it's text and its similarity\n",
    "    \"\"\"\n",
    "    verbs = []\n",
    "    for index, (in_quotes, token) in enumerate(zip(in_quotes, sentence)):\n",
    "        if in_quotes == 0 and token.pos_ == 'VERB':\n",
    "            # Get the token of the base form\n",
    "            lemma = nlp(token.lemma_)[0]\n",
    "            best_similarity = 0\n",
    "            best_verb = ''\n",
    "            for verb in cue_verbs:\n",
    "                if lemma.similarity(verb) > best_similarity:\n",
    "                    best_similarity = lemma.similarity(verb)\n",
    "                    best_verb = verb\n",
    "            verbs.append((index, token.text, best_similarity, best_verb))\n",
    "    return verbs\n",
    "\n",
    "def center_verb(sentence, in_quotes, cue_verbs):\n",
    "    \"\"\"\n",
    "    Determines the verb which isn't between quotes with the highest similarity\n",
    "    to a cue verb, and returns its position and token\n",
    "    \"\"\"\n",
    "    top_index = 0\n",
    "    top_token = None\n",
    "    top_similarity = -1\n",
    "    for index, (in_quotes, token) in enumerate(zip(in_quotes, sentence)):\n",
    "        if in_quotes == 0 and token.pos_ == 'VERB':\n",
    "            # Get the token of the base form\n",
    "            lemma = nlp(token.lemma_)[0]\n",
    "            for verb in cue_verbs:\n",
    "                if lemma.similarity(verb) > top_similarity:\n",
    "                    top_similarity = lemma.similarity(verb)\n",
    "                    top_token = token\n",
    "                    top_index = index\n",
    "    return top_index, top_token\n",
    "    \n",
    "print(verb_similarities(s, in_quotes, cue_verbs))\n",
    "print(center_verb(s, in_quotes, cue_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guillemets Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16)\n"
     ]
    }
   ],
   "source": [
    "def guillemet_features(sentence, in_quotes):\n",
    "    \"\"\"\n",
    "    returns a 0 or 1 to indicate if the sentence contains quotes or not, as well as\n",
    "    the largest number of continuous tokens between quotes\n",
    "    \"\"\"\n",
    "    if sum(in_quotes) == 0:\n",
    "        return 0, 0\n",
    "    longest_sequence = 0\n",
    "    current_sequence = 0\n",
    "    for t in in_quotes:\n",
    "        if t == 1:\n",
    "            current_sequence += 1\n",
    "            if current_sequence > longest_sequence:\n",
    "                longest_sequence = current_sequence\n",
    "        else:\n",
    "            current_sequence = 0\n",
    "    return 1, longest_sequence\n",
    "\n",
    "print(guillemet_features(s, in_quotes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_features(sentence):\n",
    "    \"\"\"\n",
    "    Features indicating whether the sentence contains a quotation mark, a\n",
    "    named entity, a verb-cue, or a pronoun, as well as a sentence length\n",
    "    feature.\n",
    "    \n",
    "    :param sentence:\n",
    "    \"\"\"\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_features(target):\n",
    "    \"\"\"\n",
    "    Features for the relation with parent, the relation with any dependants,\n",
    "    and versions of these that included the head and dependant token.\n",
    "    \n",
    "    :param target: The target verb\n",
    "    \"\"\"\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Knowledge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def external_features(target):\n",
    "    \"\"\"\n",
    "    Position-indexed features for whether any of the tokens in the sentence\n",
    "    match a known role, organisation, or title.\n",
    "    \n",
    "    :param sentence:\n",
    "    \"\"\"\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_features(target):\n",
    "    \"\"\"\n",
    "    Features for whether the target is within quotation marks, and for whether\n",
    "    there is a verb-cue near the end of the sentence.\n",
    "    \n",
    "    :param target: The target verb\n",
    "    \"\"\"\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mais\n",
      "[ 0.277226  0.600244 -0.540657 -2.277228 -0.145105 -0.707782]\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "example_token = s[0]\n",
    "print(example_token.text)\n",
    "print(example_token.vector[:6])\n",
    "print(len(example_token.vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
